import cv2
import mediapipe as mp
import time

from enum import Enum

class FaceRegion(Enum):
    LEFT_EYE = 1
    RIGHT_EYE = 2
    LEFT_EYEBROW = 3
    RIGHT_EYEBROW = 4
    NOSE = 5
    UPPER_LIP = 6
    LOWER_LIP = 7
    INSIDE_LIP = 8

class MediapipeKPDetector():

    def __init__(self, staticMode=False, maxFaces=1, refine_landmarks=True, minDetectionCon=0.4):

        self.staticMode = staticMode
        self.maxFaces = maxFaces
        self.refine_landmarks = refine_landmarks
        self.minDetectionCon = minDetectionCon

        self.mpDraw = mp.solutions.drawing_utils
        self.mpFaceMesh = mp.solutions.face_mesh

        self.faceMesh = self.mpFaceMesh.FaceMesh(self.staticMode, self.maxFaces, self.refine_landmarks, self.minDetectionCon)
        self.drawSpec = self.mpDraw.DrawingSpec(thickness=1, circle_radius=2)

        # Load filtered indices
        self.filtered_ids = self.get_68KP_indices()
    
    #def load_source(self, path, static,):
    
    @staticmethod
    def get_68KP_indices(as_dict=False):
        """
        This function return a list with Keypoints 17-67 of the 68 keypoint model (generated by mediapipe)
        Filters the 468 points from mediapipe FaceMesh

        Keypoints 0-16 are the face contour and are not relevant

        View mesh annotation at:
        https://github.com/tensorflow/tfjs-models/blob/master/face-landmarks-detection/src/mediapipe-facemesh/keypoints.ts#L49
        """

        # Mapped to [36, 37, 38, 39, 40, 41]
        left_eye_ids = [33, 160, 158, 133, 153, 144]

        # Mapped to [42, 43, 44, 45, 46, 47]
        right_eye_ids = [362, 385, 387, 263, 373, 380]

        # Mapped to [27, 28, 29, 30, 31, 32, 33, 34, 35]
        nose_ids = [6, 195, 5, 4, 240, 97, 2, 326, 460]

        # Removed 55, 193, 156
        # Mapped to [17, 18, 19, 20, 21]
        left_eyebrow_ids = [70, 63, 105, 66, 107]

        # Removed 383, 285, 417
        # Mapped to [22, 23, 24, 25, 26]
        right_eyebrow_ids = [336, 296, 334, 293, 300] # still have to remove 1

        # Mapped to [48, 49, 50, 51, 52, 53, 54]
        lip_upper_ids = [61, 40, 37, 0, 267, 270, 291]

        # Mapped to [60, 61, 62, 63, 64, 65, 66, 67]
        lip_inside_ids = [96, 82, 13, 312, 325, 317, 14, 87]

        # Mapped to [55, 56, 57, 58, 59]
        lip_lower_ids = [91, 84, 17, 314, 321]

        if not as_dict:
            master_ids = sum([
                left_eyebrow_ids,
                right_eyebrow_ids,
                nose_ids,
                left_eye_ids,
                right_eye_ids,
                lip_upper_ids, 
                lip_lower_ids, 
                lip_inside_ids
            ], [])

            return master_ids
        
        else:
            master_ids = dict()

            master_ids[FaceRegion.LEFT_EYE] = left_eye_ids
            master_ids[FaceRegion.RIGHT_EYE] = right_eye_ids

            master_ids[FaceRegion.LEFT_EYEBROW] = left_eyebrow_ids
            master_ids[FaceRegion.RIGHT_EYEBROW] = right_eyebrow_ids

            master_ids[FaceRegion.UPPER_LIP] = lip_upper_ids
            master_ids[FaceRegion.LOWER_LIP] = lip_lower_ids
            master_ids[FaceRegion.INSIDE_LIP] = lip_inside_ids

            master_ids[FaceRegion.NOSE] = nose_ids

            return master_ids


    def findFaceMesh(self, img, draw_points=True, draw_indices=False, filtered=False):
        self.imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        self.results = self.faceMesh.process(self.imgRGB)

        faces = []

        if self.results.multi_face_landmarks:

            # Every faceLms corresponds to the landmarks of one face
            for faceLms in self.results.multi_face_landmarks:
                face = []

                for id,lm in enumerate(faceLms.landmark):

                    # Landmark x,y,z is normalized
                    # Convert them back by remultiplying width/height
                    ih, iw, ic = img.shape
                    x,y = int(lm.x*iw), int(lm.y*ih)

                    circle_radius = 2 if ih < 1000 else 6

                    if draw_points:
                        if filtered:
                            if id in self.filtered_ids:
                                if draw_indices:
                                    cv2.putText(img, str(id), (x, y), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 255, 0), 1)
                                else:
                                    cv2.circle(img, (x,y), circle_radius, (255,0,0), cv2.FILLED)
                                face.append([x,y])
                        else:
                            if draw_indices:
                                cv2.putText(img, str(id), (x, y), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 255, 0), 1)
                            else:
                                cv2.circle(img, (x,y), circle_radius, (255,0,0), cv2.FILLED)

                    if filtered and id in self.filtered_ids or not filtered:
                        face.append([x,y])


                faces.append(face)

                # Draw (filtered) landmarks
                if not draw_points:
                    self.mpDraw.draw_landmarks(img, faceLms, self.mpFaceMesh.FACEMESH_CONTOURS, self.drawSpec, self.drawSpec)

        return img, faces

# Sample usage
def main():
    use_video = True

    # Load the resource
    # cap = cv2.VideoCapture("Videos/1.mp4")
    cap = cv2.VideoCapture(0) if use_video else cv2.imread('../../images/paralysis_test.jpg') 
    pTime = 0
    detector = MediapipeKPDetector(maxFaces=2)

    while True:
        if use_video:
            success, img = cap.read()
        else:
            img = cap

        # Call landmark generator
        img, faces = detector.findFaceMesh(img, draw_points=True, draw_indices=False, filtered=True)
        print(faces)

        if len(faces)!= 0:
            print(faces[0])

        # Calcultate FPS
        if use_video:
            cTime = time.time()
            fps = 1 / (cTime - pTime)
            pTime = cTime
            cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN,
                        3, (0, 255, 0), 3)

        cv2.imshow("Image", img)

        if use_video:
            cv2.waitKey(1)
        else:
            cv2.waitKey(0)
            break

if __name__ == "__main__":
    main()