import cv2
import mediapipe as mp
import time

from dlib import get_frontal_face_detector
from dlib import shape_predictor
from dlib import rectangle

class MediapipeKPDetector():

    def __init__(self, staticMode=False, maxFaces=2, refine_landmarks=True, minDetectionCon=0.5):

        self.staticMode = staticMode
        self.maxFaces = maxFaces
        self.refine_landmarks = refine_landmarks
        self.minDetectionCon = minDetectionCon

        self.mpDraw = mp.solutions.drawing_utils
        self.mpFaceMesh = mp.solutions.face_mesh

        self.faceMesh = self.mpFaceMesh.FaceMesh(self.staticMode, self.maxFaces, self.refine_landmarks, self.minDetectionCon)
        self.drawSpec = self.mpDraw.DrawingSpec(thickness=1, circle_radius=2)

        # Load filtered indices
        self.filtered_ids = self.get_68KP_indices()
    
    #def load_source(self, path, static,):
    
    def get_68KP_indices(self):
        """
        This function return a list with Keypoints 17-67 of the 68 keypoint model (generated by mediapipe)
        Filters the 468 points from mediapipe FaceMesh

        Keypoints 0-16 are the face contour and are not relevant

        View mesh annotation at:
        https://github.com/tensorflow/tfjs-models/blob/master/face-landmarks-detection/src/mediapipe-facemesh/keypoints.ts#L49
        """

        # Mapped to [36, 37, 38, 39, 40, 41]
        left_eye_ids = [33, 160, 158, 133, 153, 144]

        # Mapped to [42, 43, 44, 45, 46, 47]
        right_eye_ids = [362, 385, 387, 263, 373, 380]

        # Mapped to [27, 28, 29, 30, 31, 32, 33, 34, 35]
        nose_ids = [6, 195, 5, 4, 240, 97, 2, 326, 460]

        # Removed 55, 193, 156
        # Mapped to [17, 18, 19, 20, 21]
        left_eyebrow_ids = [70, 63, 105, 66, 107]

        # Removed 383, 285, 417
        # Mapped to [22, 23, 24, 25, 26]
        right_eyebrow_ids = [336, 296, 334, 293, 300] # still have to remove 1

        # Mapped to [48, 49, 50, 51, 52, 53, 54]
        lip_upper_ids = [61, 40, 37, 0, 267, 270, 291]

        # Mapped to [60, 61, 62, 63, 64, 65, 66, 67]
        lip_inside_ids = [96, 82, 13, 312, 325, 317, 14, 87]

        # Mapped to [55, 56, 57, 58, 59]
        lip_lower_ids = [91, 84, 17, 314, 321]

        master_ids = sum([
            left_eyebrow_ids,
            right_eyebrow_ids,
            nose_ids,
            left_eye_ids,
            right_eye_ids,
            lip_upper_ids, 
            lip_lower_ids, 
            lip_inside_ids
        ], [])

        return master_ids

    def findFaceMesh(self, img, draw_points=True, draw_indices=False, filtered=False):
        self.imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        self.results = self.faceMesh.process(self.imgRGB)

        faces = []

        if self.results.multi_face_landmarks:

            # Every faceLms corresponds to the landmarks of one face
            for faceLms in self.results.multi_face_landmarks:
                face = []

                for id,lm in enumerate(faceLms.landmark):

                    # Landmark x,y,z is normalized
                    # Convert them back by remultiplying width/height
                    ih, iw, ic = img.shape
                    x,y = int(lm.x*iw), int(lm.y*ih)

                    if draw_points:
                        if filtered:
                            if id in self.filtered_ids:
                                if draw_indices:
                                    cv2.putText(img, str(id), (x, y), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 255, 0), 1)
                                else:
                                    cv2.circle(img, (x,y), 2, (255,0,0), cv2.FILLED)
                                print('got here')
                                face.append([x,y])
                        else:
                            if draw_indices:
                                cv2.putText(img, str(id), (x, y), cv2.FONT_HERSHEY_PLAIN, 0.7, (0, 255, 0), 1)
                            else:
                                cv2.circle(img, (x,y), 2, (255,0,0), cv2.FILLED)

                    if filtered and id in self.filtered_ids or not filtered:
                        face.append([x,y])


                faces.append(face)

                # Draw (filtered) landmarks
                if not draw_points:
                    self.mpDraw.draw_landmarks(img, faceLms, self.mpFaceMesh.FACEMESH_CONTOURS, self.drawSpec, self.drawSpec)

        return img, faces

class MeeShapePredictor():

    def __init__(self):
        pass

# Sample usage
def main():
    use_video = False

    # Load the resource
    # cap = cv2.VideoCapture("Videos/1.mp4")
    cap = cv2.VideoCapture(0) if use_video else cv2.imread('../../images/paralysis_test.jpg') 
    pTime = 0
    detector = MediapipeKPDetector(maxFaces=2)

    while True:
        if use_video:
            success, img = cap.read()
        else:
            img = cap

        # Call landmark generator
        img, faces = detector.findFaceMesh(img, draw_points=False, draw_indices=False, filtered=False)
        print(faces)

        if len(faces)!= 0:
            print(faces[0])

        # Calcultate FPS
        if use_video:
            cTime = time.time()
            fps = 1 / (cTime - pTime)
            pTime = cTime
            cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN,
                        3, (0, 255, 0), 3)

        cv2.imshow("Image", img)

        if use_video:
            cv2.waitKey(1)
        else:
            cv2.waitKey(0)
            break

if __name__ == "__main__":
    main()