{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b1876f-4fba-46b3-bc15-99ee138e0369",
   "metadata": {},
   "source": [
    "[Mediapipe mesh website](https://google.github.io/mediapipe/solutions/face_mesh#python-solution-api)\n",
    "\n",
    "[Face landmark model ](https://arxiv.org/abs/1907.06724)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a7761ad-bf28-4e05-ac2c-f5d5f43f8bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "513c3ff6-c6f0-40e7-86e9-a827009835d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "output_path = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5987053c-8d0e-4f6b-9b65-26c522b8293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/robbedec/repos/ugent/thesis-inwe/notebooks\n"
     ]
    }
   ],
   "source": [
    "# For static images:\n",
    "IMAGE_FILES = ['./images/paralysis_test.jpg']\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=2, refine_landmarks=True, min_detection_confidence=0.5) as face_mesh:\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        image = cv2.imread(file)\n",
    "        \n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Print and draw face mesh landmarks on the image.\n",
    "        if not results.multi_face_landmarks:\n",
    "            continue\n",
    "            \n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # print('face_landmarks:', face_landmarks)\n",
    "            mp_drawing.draw_landmarks(\n",
    "              image=annotated_image,\n",
    "              landmark_list=face_landmarks,\n",
    "              connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "              landmark_drawing_spec=None,\n",
    "              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "            mp_drawing.draw_landmarks(\n",
    "              image=annotated_image,\n",
    "              landmark_list=face_landmarks,\n",
    "              connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "              landmark_drawing_spec=None,\n",
    "              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "            mp_drawing.draw_landmarks(\n",
    "              image=annotated_image,\n",
    "              landmark_list=face_landmarks,\n",
    "              connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "              landmark_drawing_spec=None,\n",
    "              connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
    "  \n",
    "        cv2.imwrite(output_path + '/out/annotated_image' + str(idx) + '.png', annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e18d5f25-09bf-4077-9b51-cba7fc6fcdf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp_drawing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9530/416966620.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For webcam input:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrawing_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp_drawing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDrawingSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthickness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircle_radius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmp_face_mesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFaceMesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_num_faces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefine_landmarks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_detection_confidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_tracking_confidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mface_mesh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mp_drawing' is not defined"
     ]
    }
   ],
   "source": [
    "# For webcam input:\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        # Draw the face mesh annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_tesselation_style())\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_contours_style())\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_iris_connections_style())\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Face Mesh', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44498bfb-5a85-4459-91ca-71940a2caa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlib import get_frontal_face_detector\n",
    "from dlib import shape_predictor\n",
    "from dlib import rectangle\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7155f193-3adf-4f52-af56-ae9bdacb91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = get_frontal_face_detector()\n",
    "predictor = shape_predictor('../mee_shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "image = cv2.imread('../../images/paralysis_test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7946db9-1a91-4729-8ad4-b84ace09bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, d = image.shape                        \n",
    "if d > 1:\n",
    "    #transform to gray \n",
    "    gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "#resize to speed up face dectection\n",
    "#height, width = gray.shape[:2]  \n",
    "newWidth=200\n",
    "ScalingFactor=width/newWidth\n",
    "newHeight=int(height/ScalingFactor)\n",
    "smallImage=cv2.resize(gray, (newWidth, newHeight), interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0fff7fa-bcff-4bf8-8168-9b798c5de718",
   "metadata": {},
   "outputs": [],
   "source": [
    "rects = detector(smallImage,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "428ad6dc-ed39-4cf4-89ac-df247fdc5657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face 0\n",
      "face 1\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "if len(rects) == 0 : \n",
    "    #if no face detected then try again with the full size image\n",
    "    rects = detector(gray,1)            \n",
    "        \n",
    "if len(rects) != 0:   \n",
    "    #now we have only one face in the image\n",
    "    #function to obtain facial landmarks using dlib \n",
    "    #given an image and a face\n",
    "    #rectangle\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "        \n",
    "        print('face {}'.format(i))\n",
    "        \n",
    "        inter_shape = np.zeros((68,2),dtype=int)\n",
    "\n",
    "        #adjust face position using the scaling factor\n",
    "        mod_rect=rectangle(\n",
    "                left=int(rect.left() * ScalingFactor), \n",
    "                top=int(rect.top() * ScalingFactor), \n",
    "                right=int(rect.right() * ScalingFactor), \n",
    "                bottom=int(rect.bottom() * ScalingFactor)\n",
    "        )\n",
    "\n",
    "        #predict facial landmarks \n",
    "        shape_dlib = predictor(image, mod_rect)   \n",
    "        #shape_dlib = predictor(gray, rect) \n",
    "        \n",
    "        #transform shape object to np.matrix type\n",
    "        for k in range(0,68):\n",
    "            \n",
    "            inter_shape[k] = (shape_dlib.part(k).x, shape_dlib.part(k).y)\n",
    "            \n",
    "            if inter_shape[k,0]<= 0: \n",
    "                inter_shape[k,0] = 1\n",
    "                \n",
    "            if inter_shape[k,1]<= 0: \n",
    "                inter_shape[k,1] = 1\n",
    "\n",
    "        #position of the face in the image\n",
    "        _boundingbox=[int(rect.left() * ScalingFactor), \n",
    "                           int(rect.top() * ScalingFactor),\n",
    "                           int(rect.right() * ScalingFactor) - int(rect.left() * ScalingFactor),\n",
    "                           int(rect.bottom() * ScalingFactor) - int(rect.top() * ScalingFactor)]\n",
    "        \n",
    "        results.append(np.copy(inter_shape))\n",
    "\n",
    "    #it finished processing the face, now emit the results\n",
    "    #return results\n",
    "\n",
    "else: \n",
    "    # No detected faces\n",
    "    print(\"shit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2351c896-675f-4ac6-84af-74d8f3f077ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length: 2\n",
      "(68, 2)\n"
     ]
    }
   ],
   "source": [
    "print('List length: {}'.format(len(results)))\n",
    "print(results[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff6b181c-1324-4278-8839-df16d9dacbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 353 161\n",
      "1 351 187\n",
      "2 353 213\n",
      "3 356 238\n",
      "4 363 261\n",
      "5 374 284\n",
      "6 392 301\n",
      "7 412 315\n",
      "8 437 322\n",
      "9 461 317\n",
      "10 483 303\n",
      "11 502 286\n",
      "12 516 265\n",
      "13 524 243\n",
      "14 527 219\n",
      "15 529 193\n",
      "16 529 167\n",
      "17 370 146\n",
      "18 381 135\n",
      "19 395 130\n",
      "20 411 132\n",
      "21 426 138\n",
      "22 465 132\n",
      "23 479 126\n",
      "24 495 125\n",
      "25 509 131\n",
      "26 517 145\n",
      "27 443 156\n",
      "28 443 173\n",
      "29 442 189\n",
      "30 441 207\n",
      "31 421 217\n",
      "32 431 220\n",
      "33 441 223\n",
      "34 451 220\n",
      "35 460 218\n",
      "36 387 156\n",
      "37 396 149\n",
      "38 409 150\n",
      "39 420 161\n",
      "40 407 161\n",
      "41 395 161\n",
      "42 464 162\n",
      "43 477 149\n",
      "44 490 149\n",
      "45 499 158\n",
      "46 491 162\n",
      "47 478 163\n",
      "48 394 246\n",
      "49 410 239\n",
      "50 428 238\n",
      "51 437 240\n",
      "52 448 238\n",
      "53 466 241\n",
      "54 480 246\n",
      "55 469 258\n",
      "56 454 265\n",
      "57 439 266\n",
      "58 424 265\n",
      "59 407 259\n",
      "60 400 246\n",
      "61 423 246\n",
      "62 438 247\n",
      "63 452 245\n",
      "64 475 248\n",
      "65 454 257\n",
      "66 438 259\n",
      "67 423 258\n",
      "0 49 165\n",
      "1 49 192\n",
      "2 53 218\n",
      "3 59 242\n",
      "4 67 266\n",
      "5 79 287\n",
      "6 99 302\n",
      "7 122 312\n",
      "8 148 315\n",
      "9 172 306\n",
      "10 192 291\n",
      "11 209 273\n",
      "12 220 253\n",
      "13 226 230\n",
      "14 227 205\n",
      "15 228 180\n",
      "16 227 156\n",
      "17 61 145\n",
      "18 70 133\n",
      "19 85 128\n",
      "20 103 129\n",
      "21 120 134\n",
      "22 158 122\n",
      "23 173 114\n",
      "24 189 111\n",
      "25 205 116\n",
      "26 214 130\n",
      "27 137 149\n",
      "28 138 163\n",
      "29 139 178\n",
      "30 140 193\n",
      "31 125 214\n",
      "32 134 213\n",
      "33 143 211\n",
      "34 152 208\n",
      "35 159 205\n",
      "36 81 154\n",
      "37 90 148\n",
      "38 103 147\n",
      "39 115 156\n",
      "40 103 158\n",
      "41 90 159\n",
      "42 159 153\n",
      "43 172 144\n",
      "44 184 143\n",
      "45 193 149\n",
      "46 185 152\n",
      "47 173 152\n",
      "48 115 257\n",
      "49 131 243\n",
      "50 146 233\n",
      "51 154 233\n",
      "52 161 228\n",
      "53 172 230\n",
      "54 179 238\n",
      "55 177 249\n",
      "56 171 255\n",
      "57 161 258\n",
      "58 148 258\n",
      "59 132 259\n",
      "60 126 254\n",
      "61 143 243\n",
      "62 154 238\n",
      "63 163 234\n",
      "64 174 239\n",
      "65 167 247\n",
      "66 157 250\n",
      "67 144 249\n"
     ]
    }
   ],
   "source": [
    "for i, val in enumerate(results):\n",
    "    for j, (x, y) in enumerate(val):\n",
    "        print(j, x, y)\n",
    "        cv2.circle(image, (x,y), 2, (255,0,0), cv2.FILLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda29256-c87f-41f0-852e-796526ac692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
